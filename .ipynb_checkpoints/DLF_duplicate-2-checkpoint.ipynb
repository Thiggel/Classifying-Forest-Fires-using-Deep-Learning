{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "98PM2vPmkK4q"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !unzip \"/content/drive/MyDrive/DLF/species_classification.zip\" -d \"/content\"\n",
    "# !pip install git+https://github.com/PyTorchLightning/pytorch-lightning\n",
    "# !pip install timm \n",
    "# #DOES GITHUB WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UxX5Xs4qIVXu"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Filipe Laitenberger\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from os import walk\n",
    "from os.path import join\n",
    "from PIL.Image import open\n",
    "from torchvision.transforms import PILToTensor, Compose, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class TreeSpeciesClassification(Dataset):\n",
    "    def __init__(self, image_dir: str) -> None:\n",
    "        \"\"\"\n",
    "        This dataset provides pictures of tree tops (from above) and their\n",
    "        corresponding labels\n",
    "        :param image_dir: the path to the folder that contains the dataset's images\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # create an array that contains all image paths\n",
    "        # in the dataset, by flattening the directory structure\n",
    "        self.images = [join(path, name) for path, _, files in walk(image_dir) for name in files]\n",
    "\n",
    "        # The images are transformed to tensors and augmented\n",
    "        self.transform = Compose([\n",
    "            # transform the image to a tensor\n",
    "            PILToTensor(),\n",
    "\n",
    "            # randomly flip the image horizontally, and vertically\n",
    "            # we don't rotate the images since that would leave\n",
    "            # some pixels black which could inhibit learning\n",
    "            RandomHorizontalFlip(0.5),\n",
    "            RandomVerticalFlip(0.5),\n",
    "\n",
    "            # randomly change the brightness, contrast, and\n",
    "            # saturation of the images\n",
    "            ColorJitter(\n",
    "                brightness=(0.5, 1.5),\n",
    "                contrast=(0.5, 1.5),\n",
    "                saturation=(0.5, 1.5)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.labels = {\n",
    "            'Bi': 'Birch',\n",
    "            'Bu': 'Beech',\n",
    "            'Dgl': 'Douglas fir',\n",
    "            'Ei': 'Oak',\n",
    "            'Eis': 'Damaged Oak',\n",
    "            'Erl': 'Alder',\n",
    "            'Fi': 'Spruce',\n",
    "            'Ki': 'Pine',\n",
    "            'La': 'Larch',\n",
    "            'Sch': 'Shadow / background'\n",
    "        }\n",
    "\n",
    "    def load_image(self, index: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Load the index'th image from the dataset. The images are traversed such that\n",
    "        the image with index 0 is the first image from the first sub folder of the dataset,\n",
    "        and if, for instance, the first folder contains 1000 images, then the index 1000\n",
    "        corresponds to the first image of the second sub folder, and so on.\n",
    "        The image is then transformed to a tensor and augmented (randomly flipped, and the\n",
    "        contrast/brightness/saturation is randomly changed)\n",
    "        :param index: the index of the image in the flattened file structure\n",
    "        :return: the transformed image\n",
    "        \"\"\"\n",
    "        image = open(self.images[index]).convert(\"RGB\")\n",
    "\n",
    "        return self.transform(image).float()\n",
    "\n",
    "    def load_target(self, index: int) -> int:\n",
    "        \"\"\"\n",
    "        Load the index of the target class\n",
    "        :param index: the index of the image in the flattened\n",
    "        folder structure\n",
    "        :return: the target class's index\n",
    "        \"\"\"\n",
    "        label = self.images[index].split('/')[-2]\n",
    "        return list(self.labels.keys()).index(label)\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[Tensor, int]:\n",
    "        \"\"\"\n",
    "        Load a data point\n",
    "        :param index: the index of the image in the flattened\n",
    "        folder structure\n",
    "        :return: a tuple containing the transformed image\n",
    "        and the target class's index\n",
    "        \"\"\"\n",
    "        return self.load_image(index), self.load_target(index)\n",
    "\n",
    "    @property\n",
    "    def num_classes(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the number of classes in the dataset\n",
    "        :return: the number of classes (10)\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the number of images in the dataset.\n",
    "        This doesn't take into account that images will\n",
    "        be randomly augmented (flipped + contrast/saturation/brightness changed),\n",
    "        but those transforms are partly performed within continuous ranges,\n",
    "        so that they will create infinitely many variations of the images.\n",
    "        Hence, only the original number of images is returned here\n",
    "        :return: the number of images in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "giqo-DwDkpnd"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Filipe Laitenberger\n",
    "\"\"\"\n",
    "\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import Dataset, random_split, Subset, DataLoader\n",
    "from typing import Sequence, List\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TreeSpeciesClassificationDataModule(LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 32) -> None:\n",
    "        \"\"\"\n",
    "        This dataloader splits the dataset into a training set, a validation set,\n",
    "        and a test set, and provides data loaders for all of them\n",
    "        :param batch_size: The size of each batch of image/target pairs\n",
    "        used for stochastic gradient decent (or one of its variants)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.dataset = TreeSpeciesClassification(image_dir='content/species_classification')\n",
    "\n",
    "        self.train, self.test, self.val = self.split_dataset(self.dataset)\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self.dataset.num_classes\n",
    "\n",
    "    @staticmethod\n",
    "    def split_dataset(dataset: Dataset) -> List[Subset[Dataset]]:\n",
    "        \"\"\"\n",
    "        Split a dataset into a training set, a validation set,\n",
    "        and a test set\n",
    "        :param dataset: the dataset that is to be split\n",
    "        :return: a list of three subsets of the original dataset (train/test/val)\n",
    "        \"\"\"\n",
    "        size = dataset.__len__()\n",
    "\n",
    "        # get 70% for the train set\n",
    "        train_size = int(size // 1.25)\n",
    "\n",
    "        # 20% for test set\n",
    "        test_size = int(size // 5)\n",
    "\n",
    "        # get 10% for val set\n",
    "        val_size = int(size - train_size - test_size)\n",
    "\n",
    "        lengths: Sequence = [train_size, test_size, val_size]\n",
    "\n",
    "        return random_split(dataset, lengths)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Get a data loader that shuffles and provides batches of the training set\n",
    "        :return: the training data loader\n",
    "        \"\"\"\n",
    "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True, num_workers=12)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Get a data loader that shuffles and provides batches of the validation set\n",
    "        :return: the validation data loader\n",
    "        \"\"\"\n",
    "        return DataLoader(self.val, batch_size=self.batch_size, num_workers=12)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Get a data loader that shuffles and provides batches of the test set\n",
    "        :return: the test data loader\n",
    "        \"\"\"\n",
    "        return DataLoader(self.test, batch_size=self.batch_size, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XInvR0qfnt5N"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Filipe Laitenberger\n",
    "\"\"\"\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from torch.optim import Adam, Optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pytorch_lightning.utilities.types import LRSchedulerType\n",
    "from torch import Tensor, save, load\n",
    "from torch.nn.functional import cross_entropy\n",
    "from os.path import isfile\n",
    "from typing import Tuple, List\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class TreeClassificationModel(LightningModule):\n",
    "    def __init__(self, learning_rate: float = 0.05, filename: str = 'model.pt') -> None:\n",
    "        \"\"\"\n",
    "        This class serves as an abstract class that implements methods\n",
    "        both models in this study use, like the training/validation/testing steps\n",
    "        and configurations options such as optimizers and schedulers\n",
    "        :param learning_rate: The learning rate of the model\n",
    "        :param filename: The filename under which it will be saved after each epoch\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.filename = filename\n",
    "        self.learning_rate = learning_rate\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self) -> Tuple[List[Optimizer], List[LRSchedulerType]]:\n",
    "        \"\"\"\n",
    "        This methods specifies the optimizer and learning rate scheduler.\n",
    "        We use ADAM and a ReduceOnPlateau learning rate scheduler that\n",
    "        multiplies the learning rate by 0.1 if the training loss doesn't\n",
    "        decrease for three epochs\n",
    "        :return: the optimizer and learning rate scheduler\n",
    "        \"\"\"\n",
    "        optimizer = Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': ReduceLROnPlateau(optimizer, patience=3),\n",
    "            'monitor': 'train_loss'\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch: Tensor, _) -> Tensor:\n",
    "        \"\"\"\n",
    "        A training step\n",
    "        :param batch: the batch tensor\n",
    "        :return: the loss of the batch under the current model\n",
    "        \"\"\"\n",
    "        # get columns of batch\n",
    "        images, targets = batch\n",
    "\n",
    "        predicted = self.forward(images)\n",
    "        loss = cross_entropy(predicted, targets)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Tensor, _) -> Tensor:\n",
    "        \"\"\"\n",
    "        A validation step\n",
    "        :param batch: the batch tensor\n",
    "        :return: the loss of the batch under the current model\n",
    "        \"\"\"\n",
    "        # get columns of batch\n",
    "        images, targets = batch\n",
    "\n",
    "        predicted = self.forward(images)\n",
    "        loss = cross_entropy(predicted, targets)\n",
    "        accuracy = self.accuracy(predicted, targets)\n",
    "\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', accuracy)\n",
    "\n",
    "        print('Validation Loss: ', loss)\n",
    "        print('Validation Accuracy: ', accuracy)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch: Tensor, _) -> Tensor:\n",
    "        \"\"\"\n",
    "        A test step\n",
    "        :param batch: the batch tensor\n",
    "        :return: the loss of the batch under the current model\n",
    "        \"\"\"\n",
    "        # get columns of batch\n",
    "        images, targets = batch\n",
    "\n",
    "        predicted = self.forward(images)\n",
    "        loss = cross_entropy(predicted, targets)\n",
    "        accuracy = self.accuracy(predicted, targets)\n",
    "\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', accuracy)\n",
    "\n",
    "        print('Test Loss: ', loss)\n",
    "        print('Test Accuracy: ', accuracy)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, _) -> None:\n",
    "        \"\"\"\n",
    "        At the end of each epoch we save the model\n",
    "        \"\"\"\n",
    "        self.save()\n",
    "\n",
    "    def save(self) -> None:\n",
    "        \"\"\"\n",
    "        Save model under specified filename\n",
    "        \"\"\"\n",
    "        print(\"Saving model at: \" + self.filename)\n",
    "        save(self.state_dict(), self.filename)\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"\n",
    "        Load model from the filename provided\n",
    "        \"\"\"\n",
    "        if isfile(self.filename):\n",
    "            print(\"Loading model from: \" + self.filename)\n",
    "            self.load_state_dict(load(self.filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iq9XzgXDkwUQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Mohamed Gamil\n",
    "        Thijs van der Laan\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LeNet5(TreeClassificationModel):\n",
    "    def __init__(self, num_classes: int, learning_rate: float = 0.05, filename: str = 'model.pt') -> None:\n",
    "        \"\"\"\n",
    "        This class implements the Lenet-5 model proposed by Yann LeCunn in 1998\n",
    "        :param num_classes: The number of classes in the dataset\n",
    "        :param learning_rate: The learning rate for performing gradient descent\n",
    "        :param filename: The filename under which the model is saved after every epoch\n",
    "        \"\"\"\n",
    "        super().__init__(learning_rate, filename)\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(7744, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(120, 84, kernel_size=(5, 5), stride=(1, 1), padding=0),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        feed images through the model\n",
    "        :param x: The images\n",
    "        :return: A tensor of class probabilities\n",
    "        \"\"\"\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S8s-3ZYNl_GQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Filipe Laitenberger\n",
    "\"\"\"\n",
    "\n",
    "import timm\n",
    "from torch.nn import Linear, Softmax\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Xception(TreeClassificationModel):\n",
    "    def __init__(self, num_classes: int, learning_rate: float = 0.05, filename: str = 'model.pt') -> None:\n",
    "        \"\"\"\n",
    "        This model is an image classifier inspired by the 'Xception' model\n",
    "        :param num_classes: The number of classes in the dataset\n",
    "        :param learning_rate: The learning rate for performing gradient descent\n",
    "        :param filename: The filename under which the model is saved after every epoch\n",
    "        \"\"\"\n",
    "        super().__init__(learning_rate, filename)\n",
    "\n",
    "        # we use a predefined model 'Xception' as it is\n",
    "        # one of the state of the art networks\n",
    "        self.model = timm.create_model('xception')\n",
    "\n",
    "        # change the last layer of the network to map to the\n",
    "        # classes of our dataset\n",
    "        self.model.fc = Linear(2048, num_classes)\n",
    "\n",
    "        self.softmax = Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        feed images through the model\n",
    "        :param x: The images\n",
    "        :return: A tensor of class probabilities\n",
    "        \"\"\"\n",
    "        return self.softmax(self.model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784,
     "referenced_widgets": [
      "66cd00c6024b417889642e064d53ac14",
      "b9be05d866734f00b6da1ae8f8f5a313",
      "468bf217b02d45db8488ad011d847bc5",
      "30560c5a4e56445ba50735736ee1781a",
      "a2c22de56c914477ac8f5f05b1b0c102",
      "04d4c9e84073466eb261101abf62458f",
      "8c5d508f3da54988bd3c754c66f23641",
      "9d9c8aa808f34c21b523fbacc8b3ce8a",
      "9a6c3d6dd5634cc4aa6c33a380148282",
      "1f71fdda1db742f8b9b6acf1e86e10df",
      "f8cf1a25a4774300ad9c0fc5af21b95b"
     ]
    },
    "id": "g_TN30s-k70w",
    "outputId": "7b29d574-59f7-4986-828b-b8b81cc76f74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | accuracy | Accuracy | 0     \n",
      "1 | model    | Xception | 20.8 M\n",
      "2 | softmax  | Softmax  | 0     \n",
      "--------------------------------------\n",
      "20.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.8 M    Total params\n",
      "83.310    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: xception.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7790099f604ffbb18dde7b6da6c760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "Total length of `Dataloader` across ranks is zero. Please make sure that it returns at least 1 batch.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-605843346ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-605843346ef7>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, data_module)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# test the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    738\u001b[0m             )\n\u001b[1;32m    739\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         self._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    741\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;31m# reload dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reload_evaluation_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36m_reload_evaluation_dataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_test_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloaders\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_reload_val_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_val_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_evaluation_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py\u001b[0m in \u001b[0;36mreset_val_dataloader\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mhas_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_overridden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             self.num_val_batches, self.val_dataloaders = self._reset_eval_dataloader(\n\u001b[0m\u001b[1;32m    552\u001b[0m                 \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpl_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py\u001b[0m in \u001b[0;36m_reset_eval_dataloader\u001b[0;34m(self, mode, model)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 orig_num_batches = num_batches = (\n\u001b[1;32m    507\u001b[0m                     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mhas_len_all_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py\u001b[0m in \u001b[0;36mhas_len_all_ranks\u001b[0;34m(dataloader, training_type, model)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             raise MisconfigurationException(\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;34m\"Total length of `Dataloader` across ranks is zero. Please make sure that it returns at least 1 batch.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             )\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: Total length of `Dataloader` across ranks is zero. Please make sure that it returns at least 1 batch."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Filipe Laitenberger\n",
    "\"\"\"\n",
    "\n",
    "from pytorch_lightning import Trainer, LightningModule, LightningDataModule\n",
    "from torch import cuda\n",
    "\n",
    "\n",
    "\n",
    "def run_model(model: LightningModule, data_module: LightningDataModule) -> None:\n",
    "    \"\"\"\n",
    "    Run a model out of the two used in this experiment (xception or lenet5)\n",
    "    and do some repetetive steps such as calculating the learning rate\n",
    "    :param model: A pytorch-lightning model\n",
    "    \"\"\"\n",
    "    # load the model if it exists already\n",
    "    model.load()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=100,\n",
    "        # if GPUs are available, use all of them\n",
    "        gpus=(-1 if cuda.is_available() else 0)\n",
    "    )\n",
    "\n",
    "    # calculate optimal learning rate\n",
    "    # lr_finder = trainer.tuner.lr_find(model, datamodule=data_module)\n",
    "    # model.learning_rate = lr_finder.suggestion()\n",
    "\n",
    "    # train the network\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    # test the network\n",
    "    trainer.test(model, data_module)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Run the experiment by training and testing the two models\n",
    "    (Xception and LeNet-5)\n",
    "    \"\"\"\n",
    "\n",
    "    data_module = TreeSpeciesClassificationDataModule()\n",
    "\n",
    "    models = [\n",
    "        Xception(num_classes=data_module.num_classes, filename='xception.pt'),\n",
    "        LeNet5(num_classes=data_module.num_classes, filename='lenet5.pt')\n",
    "    ]\n",
    "\n",
    "    for model in models:\n",
    "        run_model(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DLF-duplicate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04d4c9e84073466eb261101abf62458f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f71fdda1db742f8b9b6acf1e86e10df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30560c5a4e56445ba50735736ee1781a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f71fdda1db742f8b9b6acf1e86e10df",
      "placeholder": "​",
      "style": "IPY_MODEL_f8cf1a25a4774300ad9c0fc5af21b95b",
      "value": " 0/? [00:00&lt;?, ?it/s]"
     }
    },
    "468bf217b02d45db8488ad011d847bc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d9c8aa808f34c21b523fbacc8b3ce8a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a6c3d6dd5634cc4aa6c33a380148282",
      "value": 0
     }
    },
    "66cd00c6024b417889642e064d53ac14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b9be05d866734f00b6da1ae8f8f5a313",
       "IPY_MODEL_468bf217b02d45db8488ad011d847bc5",
       "IPY_MODEL_30560c5a4e56445ba50735736ee1781a"
      ],
      "layout": "IPY_MODEL_a2c22de56c914477ac8f5f05b1b0c102"
     }
    },
    "8c5d508f3da54988bd3c754c66f23641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a6c3d6dd5634cc4aa6c33a380148282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d9c8aa808f34c21b523fbacc8b3ce8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2c22de56c914477ac8f5f05b1b0c102": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b9be05d866734f00b6da1ae8f8f5a313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04d4c9e84073466eb261101abf62458f",
      "placeholder": "​",
      "style": "IPY_MODEL_8c5d508f3da54988bd3c754c66f23641",
      "value": "Sanity Checking: "
     }
    },
    "f8cf1a25a4774300ad9c0fc5af21b95b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
